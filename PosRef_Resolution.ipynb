{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/manuelnunezmartinez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/manuelnunezmartinez/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dependency parsing and coreference resolution \n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Sentiment analysis \n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# csv parsing \n",
    "import csv\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is used to visualaize a depensncy tree using an nlp doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses displacy to visualize a sentences dependency tree \n",
    "\n",
    "def visualize_dependency_tree(doc):\n",
    "    \n",
    "    # Visualize the dependency tree\n",
    "    displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Function below is used to recoginize multi-word entities as one particular entity when dependency parsing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retokenize_entities(doc):\n",
    "\n",
    "    # Step 1: Identify Multi-Word Named Entities\n",
    "    multi_word_entities = []\n",
    "    for ent in doc.ents:\n",
    "        if len(ent) > 1:\n",
    "            multi_word_entities.append(ent)\n",
    "\n",
    "    # Step 2: Merge Tokens\n",
    "    for ent in multi_word_entities:\n",
    "        with doc.retokenize() as retokenizer:\n",
    "            start = ent.start\n",
    "            end = ent.end\n",
    "            retokenizer.merge(doc[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first function below we pass in a dictionary of adjectives/verbs as keys pointing at the nouns they describe, flipping that dictionary, and returning a dictionary of nouns as keys pointing at the adjectives describing/verbs them\n",
    "\n",
    "The second function takes in as input a dictionary of nounc pointing to verbs/adjectives and returns same dictionary with the adjectives/verbs substitutes for their valence scors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_relations(relations):\n",
    "    sent_dic = {}\n",
    "\n",
    "    for key in relations:\n",
    "        for ref in relations[key]:\n",
    "            if ref not in sent_dic:\n",
    "                sent_dic[ref] = [key]\n",
    "            else:\n",
    "                sent_dic[ref].append(key)\n",
    "\n",
    "    for key, value in sent_dic.items():\n",
    "        sent_dic[key] = sorted(value)\n",
    "\n",
    "    return sent_dic\n",
    "\n",
    "\n",
    "def vectorize_dic(sent_dic):\n",
    "    for key in sent_dic:\n",
    "        sentiment = 0\n",
    "        for adj in sent_dic[key]:\n",
    "            adj_blob = TextBlob(adj)\n",
    "            adj_sentiment = adj_blob.sentiment.polarity\n",
    "            sentiment += adj_sentiment\n",
    "        sent_dic[key] = sentiment\n",
    "    return sent_dic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function provides a simple approach to finding relations between adjectives and nouns. It was ultimatley not use given its limited scope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-26 18:44:50.129685: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: []\n",
      "mouse: []\n"
     ]
    }
   ],
   "source": [
    "def extract_nouns(sentence):\n",
    "    # Load SpaCy model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Process the input sentence\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Initialize a dictionary to store nouns and their references\n",
    "    noun_dict = {}\n",
    "    \n",
    "    # Iterate through each token in the sentence\n",
    "    for token in doc:\n",
    "        # Check if the token is a noun\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            # If the noun is not in the dictionary, add it as a key\n",
    "            if token.text not in noun_dict:\n",
    "                noun_dict[token.text] = []\n",
    "            # Iterate through children of the noun\n",
    "            for child in token.children:\n",
    "                # If the child is an adjective modifying the noun, add it to the list of references\n",
    "                if child.dep_ == \"amod\":\n",
    "                    noun_dict[token.text].append(child.text)\n",
    "                # If the child is a possessive case modifying the noun, add it to the list of references\n",
    "                elif child.dep_ == \"poss\":\n",
    "                    noun_dict[token.text].append(child.text + \"'s\")\n",
    "    \n",
    "    return noun_dict\n",
    "\n",
    "# Example sentence\n",
    "sentence = \"The cat chased the mouse. The mouse ran away.\"\n",
    "\n",
    "# Extract nouns and their references\n",
    "noun_references = extract_nouns(sentence)\n",
    "\n",
    "# Print the dictionary\n",
    "for noun, references in noun_references.items():\n",
    "    print(f\"{noun}: {references}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of functions below efficiently find the closest instance of a POS to another POS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distances(sentence, from_pos, to_pos):   \n",
    "    sent_dic = {}\n",
    "    # Create memoization array \n",
    "    mem = [(-1, \"\")] * len(sentence)\n",
    "\n",
    "    #mark closest predecessors \n",
    "    mark_down(sentence.root, to_pos, mem)\n",
    "    \n",
    "    #consider succesors and finalize dictionary \n",
    "    for token in sentence:\n",
    "        if token.pos_ in from_pos:\n",
    "            # cretae dictionary entry for token\n",
    "            if token.text not in sent_dic:\n",
    "                sent_dic[token.text] = []\n",
    "            \n",
    "            if token != sentence.root:\n",
    "                mark_up(token, mem, token.head, 1)\n",
    "            \n",
    "            sent_dic[token.text].append(mem[token.i][1])\n",
    "            \n",
    "\n",
    "    return sent_dic\n",
    "\n",
    "\n",
    "# check parent node recursivley as long as current distance from a noun isnt surpassed \n",
    "def mark_up(ref, mem, token, dist):\n",
    "    closest = mem[token.i][0]\n",
    "    if closest != -1 and (closest + dist < mem[ref.i][0] or mem[ref.i][0] == -1):\n",
    "        mem[ref.i] = (mem[token.i][0] + dist, mem[token.i][1])\n",
    "    \n",
    "    if token.dep_ != \"ROOT\":\n",
    "        mark_up(ref, mem, token.head, dist + 1)\n",
    "\n",
    "\n",
    "# mark all entires in memoization array with closest noun succesor \n",
    "def mark_down(token, to_pos, mem):\n",
    "    if token.pos_ in to_pos:\n",
    "        mem[token.i] = (0, token.text)\n",
    "\n",
    "    dist = (10000, \"\")\n",
    "    for child in token.children:\n",
    "        mark_down(child, to_pos, mem)\n",
    "        closest = mem[child.i][0]\n",
    "        if closest != -1 and closest < dist[0]:\n",
    "            dist = (closest, mem[child.i][1])\n",
    "        \n",
    "    if dist[0] != 10000 and token.pos_ not in to_pos:\n",
    "        update = (dist[0] + 1, dist[1])\n",
    "        mem[token.i] = update\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the POS relation algorithm which simply relies on the closest relation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-04 16:20:20.725495: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"8db49ad335004402b537e4a6c2f7eec8-0\" class=\"displacy\" width=\"2150\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Dear</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Media:</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Please,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">INTJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">too,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">stop</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">assuming</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Democrats</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">will</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">lose</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">midterms.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8db49ad335004402b537e4a6c2f7eec8-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8db49ad335004402b537e4a6c2f7eec8-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8db49ad335004402b537e4a6c2f7eec8-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8db49ad335004402b537e4a6c2f7eec8-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">intj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8db49ad335004402b537e4a6c2f7eec8-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8db49ad335004402b537e4a6c2f7eec8-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8db49ad335004402b537e4a6c2f7eec8-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8db49ad335004402b537e4a6c2f7eec8-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8db49ad335004402b537e4a6c2f7eec8-0-4\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8db49ad335004402b537e4a6c2f7eec8-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8db49ad335004402b537e4a6c2f7eec8-0-5\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,89.5 1620.0,89.5 1620.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8db49ad335004402b537e4a6c2f7eec8-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8db49ad335004402b537e4a6c2f7eec8-0-6\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8db49ad335004402b537e4a6c2f7eec8-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8db49ad335004402b537e4a6c2f7eec8-0-7\" stroke-width=\"2px\" d=\"M945,264.5 C945,2.0 1625.0,2.0 1625.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8db49ad335004402b537e4a6c2f7eec8-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1625.0,266.5 L1633.0,254.5 1617.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8db49ad335004402b537e4a6c2f7eec8-0-8\" stroke-width=\"2px\" d=\"M1820,264.5 C1820,177.0 1965.0,177.0 1965.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8db49ad335004402b537e4a6c2f7eec8-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,266.5 L1812,254.5 1828,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8db49ad335004402b537e4a6c2f7eec8-0-9\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,89.5 1970.0,89.5 1970.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8db49ad335004402b537e4a6c2f7eec8-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1970.0,266.5 L1978.0,254.5 1962.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Media': ['Dear']}\n",
      "{}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m visualize_dependency_tree(doc)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msents:\n\u001b[0;32m---> 11\u001b[0m     relations_adj \u001b[38;5;241m=\u001b[39m \u001b[43mfind_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mADJ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNOUN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPROPN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     relation_dic_adj \u001b[38;5;241m=\u001b[39m format_relations(relations_adj)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(relation_dic_adj)\n",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36mfind_distances\u001b[0;34m(sentence, from_pos, to_pos)\u001b[0m\n\u001b[1;32m      4\u001b[0m mem \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(sentence)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#mark closest predecessors \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmark_down\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#consider succesors and finalize dictionary \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m sentence:\n",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m, in \u001b[0;36mmark_down\u001b[0;34m(token, to_pos, mem)\u001b[0m\n\u001b[1;32m     40\u001b[0m dist \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m token\u001b[38;5;241m.\u001b[39mchildren:\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mmark_down\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     closest \u001b[38;5;241m=\u001b[39m mem[child\u001b[38;5;241m.\u001b[39mi][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m closest \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m closest \u001b[38;5;241m<\u001b[39m dist[\u001b[38;5;241m0\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m, in \u001b[0;36mmark_down\u001b[0;34m(token, to_pos, mem)\u001b[0m\n\u001b[1;32m     40\u001b[0m dist \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m token\u001b[38;5;241m.\u001b[39mchildren:\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mmark_down\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     closest \u001b[38;5;241m=\u001b[39m mem[child\u001b[38;5;241m.\u001b[39mi][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m closest \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m closest \u001b[38;5;241m<\u001b[39m dist[\u001b[38;5;241m0\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m, in \u001b[0;36mmark_down\u001b[0;34m(token, to_pos, mem)\u001b[0m\n\u001b[1;32m     40\u001b[0m dist \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m token\u001b[38;5;241m.\u001b[39mchildren:\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mmark_down\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     closest \u001b[38;5;241m=\u001b[39m mem[child\u001b[38;5;241m.\u001b[39mi][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m closest \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m closest \u001b[38;5;241m<\u001b[39m dist[\u001b[38;5;241m0\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[6], line 38\u001b[0m, in \u001b[0;36mmark_down\u001b[0;34m(token, to_pos, mem)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmark_down\u001b[39m(token, to_pos, mem):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;129;01min\u001b[39;00m to_pos:\n\u001b[0;32m---> 38\u001b[0m         \u001b[43mmem\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, token\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     40\u001b[0m     dist \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m token\u001b[38;5;241m.\u001b[39mchildren:\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "document = \"Dear Media: Please, too, stop assuming the Democrats will lose the midterms.\"\n",
    "# Load spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Process the input sentence\n",
    "doc = nlp(document)\n",
    "retokenize_entities(doc)\n",
    "\n",
    "visualize_dependency_tree(doc)\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    relations_adj = find_distances(sentence, [\"ADJ\"], [\"NOUN\", \"PROPN\"])\n",
    "    relation_dic_adj = format_relations(relations_adj)\n",
    "    print(relation_dic_adj)\n",
    "\n",
    "    relations_verb = find_distances(sentence, [\"VERB\"], [\"NOUN\", \"PROPN\"])\n",
    "    relation_dic_verb = format_relations(relations_verb)\n",
    "    print(relation_dic_verb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below parses a csv containing sentences and the human annoated relations found between nouns and adjectives/verbs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        sentence = None\n",
    "        relations = {}\n",
    "        for row in reader:\n",
    "            if not row:  # Empty line indicates new sentence\n",
    "                if sentence is not None:\n",
    "                    data.append((sentence, relations))\n",
    "                    sentence = None\n",
    "                    relations = {}\n",
    "            else:\n",
    "                if sentence is None:\n",
    "                    sentence = ','.join(row)\n",
    "                else:\n",
    "                    row_str = ','.join(row)\n",
    "                    noun, referenced_string = row_str.split(': ')\n",
    "                    references = referenced_string.split(',')\n",
    "                    relations[noun] = references\n",
    "        if sentence is not None:  # Add the last sentence\n",
    "            data.append((sentence, relations))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we test the POS refrence algorithm above to find precision and recall metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_POS_Reference(filepath, from_pos, to_pos):\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    parsed_data = parse_csv(filepath)\n",
    "\n",
    "    total_present_relations = 0\n",
    "    total_predicted_relations = 0\n",
    "    total_correct_predictions = 0\n",
    "\n",
    "    # for each sentence considered \n",
    "    for entry in parsed_data:\n",
    "        # Process the input sentence\n",
    "        doc = nlp(entry[0])\n",
    "        retokenize_entities(doc)\n",
    "        for sentence in doc.sents:\n",
    "            #find and format relations through proximity \n",
    "            relations = find_distances(sentence, from_pos, to_pos)\n",
    "            relation_dic = format_relations(relations)\n",
    "\n",
    "            # add onto the total number of relations considered \n",
    "            for value in entry[1].values():\n",
    "                total_present_relations += len(value)\n",
    "            \n",
    "            for value in relation_dic.values():\n",
    "                total_predicted_relations += len(value)\n",
    "\n",
    "            # check which relations were correctly predicted \n",
    "            correct = True\n",
    "            for key in relation_dic:\n",
    "                    if key in entry[1]:\n",
    "                        for val in relation_dic[key]:\n",
    "                            if val in entry[1][key]:\n",
    "                                total_correct_predictions += 1\n",
    "                            else:\n",
    "                                # print(entry[0])\n",
    "                                # print(f\"Right Noun, Wrong Relation: {key} -> {val}\")\n",
    "                                # print()\n",
    "                                correct = False\n",
    "                    else:\n",
    "                        # print(entry[0])\n",
    "                        # print(f\"Nonexistent Reference: {key} -> {relation_dic[key]}\")\n",
    "                        # print()\n",
    "                        correct = False\n",
    "            # visualize dependency tree if relations are incorrect \n",
    "            # if not correct:\n",
    "            #     print(\"Relations found:\",relation_dic)\n",
    "            #     visualize_dependency_tree(doc)\n",
    "\n",
    "    print(\"Percent of present relations outputted:\", (total_correct_predictions/total_present_relations))\n",
    "    print(\"Percent of correct predictions:\", (total_correct_predictions/total_predicted_relations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of present relations outputted: 0.7887323943661971\n",
      "Percent of correct predictions: 0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "test_POS_Reference('POS_test_ADJ.csv', ['ADJ', 'ADV'], ['NOUN', 'PROPN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of present relations outputted: 0.6329113924050633\n",
      "Percent of correct predictions: 0.684931506849315\n"
     ]
    }
   ],
   "source": [
    "test_POS_Reference('POS_test_VERB.csv', ['VERB'], ['NOUN', 'PROPN'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
